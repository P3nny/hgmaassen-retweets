{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixes some issues when running twint in Notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "c = twint.Config()\n",
    "\n",
    "c.Username = 'hgmaassen'\n",
    "c.Proxy_host = 'tor'\n",
    "c.Store_csv = True\n",
    "c.Output = 'followers.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twint.run.Followers(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get Retweets of Followers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching the follower could have been done with the official API as well. Originally, I wanted to everything with twint but Twitter blocked the API for the requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import twitter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers = Path('followers.csv').read_text().split()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = twitter.Api(\n",
    "    '', '', '', '', sleep_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(api=None, screen_name=None):\n",
    "    timeline = api.GetUserTimeline(screen_name=screen_name, count=200)\n",
    "    if len(timeline) == 0:\n",
    "        return []\n",
    "    print(len(timeline))\n",
    "    earliest_tweet = min(timeline, key=lambda x: x.id).id\n",
    "    print(\"getting tweets before:\", earliest_tweet)\n",
    "\n",
    "    while True:\n",
    "        tweets = api.GetUserTimeline(\n",
    "            screen_name=screen_name, max_id=earliest_tweet, count=200\n",
    "        )\n",
    "        new_earliest = min(tweets, key=lambda x: x.id).id\n",
    "\n",
    "        if not tweets or new_earliest == earliest_tweet:\n",
    "            break\n",
    "        else:\n",
    "            earliest_tweet = new_earliest\n",
    "            print(\"getting tweets before:\", earliest_tweet)\n",
    "            timeline += tweets\n",
    "\n",
    "    return timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in followers:\n",
    "    if Path(f'/mnt/data/datasets/twitter/tweets-maassen/{f}.json').is_file():\n",
    "        continue\n",
    "    print(f)\n",
    "    try:\n",
    "        timeline = get_tweets(api=api, screen_name=f)\n",
    "        with open(f'/mnt/data/datasets/twitter/tweets-maassen/{f}.json', 'w+') as f:\n",
    "            for tweet in timeline:\n",
    "                f.write(json.dumps(tweet._json))\n",
    "                f.write('\\n')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
